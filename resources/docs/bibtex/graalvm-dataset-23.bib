@inproceedings{10.1145/3578245.3585025,
author = {Bulej, Lubom\'{\i}r and Hork\'{y}, Vojtech and Tucci, Michele and Tuma, Petr and Farquet, Fran\c{c}ois and Leopoldseder, David and Prokopec, Aleksandar},
title = {GraalVM Compiler Benchmark Results Dataset (Data Artifact)},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3585025},
doi = {10.1145/3578245.3585025},
abstract = {Systematic testing of software performance during development is a persistent challenge, made increasingly important by the magnifying effect of mass software deployment on any savings. In practice, such systematic performance evaluation requires a combination of an efficient and reliable measurement procedure integrated into the development environment, coupled with an automated evaluation of the measurement results and compact reporting of detected performance anomalies.A realistic evaluation of research contributions to systematic software performance testing can benefit from the availability of measurement data that comes from long term development activities in a well documented context. This paper presents a data artifact that aggregates more than 70 machine time years of performance measurements over 7 years of development of the GraalVM Compiler Project, aiming to reduce the costs of evaluating research contributions in this and similar contexts.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {65â€“69},
numpages = {5},
keywords = {benchmark, dataset, compiler},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}
